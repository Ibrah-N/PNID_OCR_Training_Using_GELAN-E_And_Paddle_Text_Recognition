{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Verifying Dataset\n"
      ],
      "metadata": {
        "id": "-yZRC4Jm69UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v4hNSYTe68o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/project-3-at-2025-05-20-14-35-1549ca81.zip -d /content"
      ],
      "metadata": {
        "id": "B2irCsou68m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv"
      ],
      "metadata": {
        "id": "AQ9iDGlm73xK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv.imread(\"/content/images/049a7787-image-4.jpg\")\n",
        "\n",
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYFeb_rTXprK",
        "outputId": "cdca8b77-34cb-4533-e2ff-0bb4ffef381a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1792, 1792, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_root_dir = \"/content/images\"\n",
        "lbl_root_dir = \"/content/labels\"\n",
        "output_dir = \"/content/output/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "path_list = os.listdir(img_root_dir)\n",
        "print(f\"Dataset Size : {len(path_list)}\")"
      ],
      "metadata": {
        "id": "5Rx9hqYm73vU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d666a48-5f98-4c3b-c9e2-107f5a303485"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size : 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def xywm_to_xyxy(yolo_bbox, img_width=1792, img_height=1792):\n",
        "    x_center, y_center, w, h = map(float, yolo_bbox)\n",
        "\n",
        "    x1 = (x_center - w / 2) * img_width\n",
        "    y1 = (y_center - h / 2) * img_height\n",
        "    x2 = (x_center + w / 2) * img_width\n",
        "    y2 = (y_center + h / 2) * img_height\n",
        "\n",
        "    return int(x1), int(y1), int(x2), int(y2)"
      ],
      "metadata": {
        "id": "Ws7iItRz73ri"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subset = np.random.choice(path_list, 10)\n",
        "\n",
        "for path in path_list:\n",
        "  ## images and label paths\n",
        "  img_path = os.path.join(img_root_dir, path)\n",
        "  lbl_path = os.path.join(lbl_root_dir, path[:-4] + \".txt\")\n",
        "\n",
        "\n",
        "  ## read image and label files\n",
        "  image = cv.imread(img_path)\n",
        "  with open(lbl_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "\n",
        "  ## parse labels\n",
        "  lines = [line.strip().split(\" \") for line in lines]\n",
        "  lines = [xywm_to_xyxy(line[1:]) for line in lines]\n",
        "  for line in lines:\n",
        "    cv.rectangle(image, (line[0], line[1]), (line[2], line[3]), (0, 255, 0), 2)\n",
        "\n",
        "  ## save the image\n",
        "  output_img_path = os.path.join(output_dir, img_path.split(\"/\")[-1])\n",
        "  cv.imwrite(output_img_path, image)\n",
        "\n",
        "  print(f\"image save at {output_img_path}\")"
      ],
      "metadata": {
        "id": "4SoiuNSi8AOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip /content/output_3.zip -r /content/output/"
      ],
      "metadata": {
        "id": "5xRr9lTG8NO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/output/"
      ],
      "metadata": {
        "id": "6eNlePUk73pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preperaing The Detection Dataset"
      ],
      "metadata": {
        "id": "0hdwD2im6yWJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUuOfcgdq4a0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q albumentations tqdm"
      ],
      "metadata": {
        "id": "kIs6HMU36M-r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/dataset_v2/"
      ],
      "metadata": {
        "id": "OXrzx7O-uqBr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Unzip the yolo format images and labels\n",
        "## Structure: -dataset\n",
        "#                - images\n",
        "#                - labels\n",
        "\n",
        "\n",
        "!unzip /content/project-3-at-2025-05-17-19-58-99bd2d3f.zip -d /content/"
      ],
      "metadata": {
        "id": "nI_lrwJ5uqAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "# Input & Output Directories\n",
        "image_dir = \"/content/images/\"  # Folder with original images\n",
        "label_dir = \"/content/labels/\"  # Folder with YOLO labels\n",
        "output_image_dir = \"rotated_images/\"  # Save rotated images\n",
        "output_label_dir = \"rotated_labels/\"  # Save updated labels\n",
        "\n",
        "# Ensure output directories exist\n",
        "os.makedirs(output_image_dir, exist_ok=True)\n",
        "os.makedirs(output_label_dir, exist_ok=True)\n",
        "\n",
        "# Define augmentation (90-degree rotation)\n",
        "transform = A.Compose([\n",
        "    A.Rotate(limit=[90, 90], p=1)  # Rotate exactly 90 degrees\n",
        "])\n",
        "\n",
        "def correct_yolo_labels_after_rotation(label_path, img_width, img_height):\n",
        "    \"\"\" Adjust YOLO bounding boxes after a 90-degree clockwise rotation. \"\"\"\n",
        "    new_labels = []\n",
        "\n",
        "    with open(label_path, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        data = line.strip().split()\n",
        "        class_id, x_center, y_center, bbox_w, bbox_h = map(float, data)\n",
        "\n",
        "        # Convert to absolute values\n",
        "        x_center_abs = x_center * img_width\n",
        "        y_center_abs = y_center * img_height\n",
        "        bbox_w_abs = bbox_w * img_width\n",
        "        bbox_h_abs = bbox_h * img_height\n",
        "\n",
        "        # Transform coordinates for 90-degree rotation\n",
        "        new_x_center_abs = y_center_abs\n",
        "        new_y_center_abs = img_width - x_center_abs\n",
        "        new_bbox_w_abs, new_bbox_h_abs = bbox_h_abs, bbox_w_abs  # Swap width & height\n",
        "\n",
        "        # Normalize back to YOLO format\n",
        "        new_x_center = new_x_center_abs / img_height\n",
        "        new_y_center = new_y_center_abs / img_width\n",
        "        new_bbox_w = new_bbox_w_abs / img_height\n",
        "        new_bbox_h = new_bbox_h_abs / img_width\n",
        "\n",
        "        new_labels.append(f\"{int(class_id)} {new_x_center} {new_y_center} {new_bbox_w} {new_bbox_h}\\n\")\n",
        "\n",
        "    return new_labels\n",
        "\n",
        "\n",
        "\n",
        "# Process all images\n",
        "for img_file in os.listdir(image_dir):\n",
        "    if img_file.endswith(\".jpg\") or img_file.endswith(\".png\"):\n",
        "        img_path = os.path.join(image_dir, img_file)\n",
        "        label_path = os.path.join(label_dir, img_file.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
        "\n",
        "        # Load Image\n",
        "        image = cv2.imread(img_path)\n",
        "        img_height, img_width = image.shape[:2]\n",
        "\n",
        "        # Rotate Image\n",
        "        augmented = transform(image=image)\n",
        "        rotated_image = augmented[\"image\"]\n",
        "\n",
        "        # Save rotated image\n",
        "        rotated_img_path = os.path.join(output_image_dir, f\"aug_0_{img_file}\")\n",
        "        cv2.imwrite(rotated_img_path, rotated_image)\n",
        "\n",
        "        # Adjust & Save YOLO labels\n",
        "        if os.path.exists(label_path):\n",
        "            new_labels = correct_yolo_labels_after_rotation(label_path, img_width, img_height)\n",
        "            rotated_label_path = os.path.join(output_label_dir, f\"aug_0_{img_file.replace('.jpg', '.txt').replace('.png', '.txt')}\")\n",
        "\n",
        "            with open(rotated_label_path, \"w\") as file:\n",
        "                file.writelines(new_labels)\n",
        "\n",
        "        print(f\"Processed: {img_file}\")\n",
        "\n",
        "print(\"Augmentation completed for all images.\")"
      ],
      "metadata": {
        "id": "m2YXgZXEup85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683ce955-f4a4-4124-b283-53fb2947432e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.6'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: e17ce386-image-7.jpg\n",
            "Processed: 6c656325-image-8.jpg\n",
            "Processed: 7354a685-image-2.jpg\n",
            "Processed: 9ebe8e73-image-13.jpg\n",
            "Processed: 4c0438f6-image-5.jpg\n",
            "Processed: db4e9248-image-13.jpg\n",
            "Processed: 2588bcad-image-12.jpg\n",
            "Processed: c6b3eda5-image-0.jpg\n",
            "Processed: 949ee203-image-5.jpg\n",
            "Processed: 36fab787-image-2.jpg\n",
            "Processed: 24a7144f-image-0.jpg\n",
            "Processed: b3d4b7e2-image-2.jpg\n",
            "Processed: 1fe06538-image-3.jpg\n",
            "Processed: 5f11dd54-image-6.jpg\n",
            "Processed: a94f9b41-image-9.jpg\n",
            "Processed: d8e116fe-image-10.jpg\n",
            "Processed: b013a0cc-image-14.jpg\n",
            "Processed: 0ddc6c33-image-6.jpg\n",
            "Processed: 96c11d3f-image-1.jpg\n",
            "Processed: 94c21519-image-0.jpg\n",
            "Processed: d615e566-image-6.jpg\n",
            "Processed: d4a77215-image-10.jpg\n",
            "Processed: bafccc6a-image-4.jpg\n",
            "Processed: 1b22a18b-image-4.jpg\n",
            "Processed: 8abf181c-image-9.jpg\n",
            "Processed: 57e061ef-image-10.jpg\n",
            "Processed: 5a6f57f2-image-14.jpg\n",
            "Processed: 559dd430-image-7.jpg\n",
            "Processed: 934f75b7-image-10.jpg\n",
            "Processed: a5b54ee1-image-5.jpg\n",
            "Processed: 0ad6ea7e-image-11.jpg\n",
            "Processed: b54bb9b3-image-14.jpg\n",
            "Processed: d862a143-image-13.jpg\n",
            "Processed: 049a7787-image-4.jpg\n",
            "Processed: 4d717a05-image-8.jpg\n",
            "Processed: e215ba40-image-13.jpg\n",
            "Processed: adc32442-image-3.jpg\n",
            "Processed: 102da4db-image-14.jpg\n",
            "Processed: 87e702db-image-7.jpg\n",
            "Processed: 1a45f509-image-0.jpg\n",
            "Processed: 804cd2cc-image-12.jpg\n",
            "Processed: 12cc78e7-image-1.jpg\n",
            "Processed: 68cd8a7c-image-3.jpg\n",
            "Processed: 58a8f5ba-image-8.jpg\n",
            "Processed: 965e0276-image-12.jpg\n",
            "Processed: fb0dd38d-image-5.jpg\n",
            "Processed: 37ed10d3-image-6.jpg\n",
            "Processed: 1f26153e-image-11.jpg\n",
            "Processed: ecbf4e26-image-3.jpg\n",
            "Processed: 2d782f68-image-9.jpg\n",
            "Processed: 5b0305e8-image-12.jpg\n",
            "Processed: c51abb2b-image-1.jpg\n",
            "Processed: 8ada4f1f-image-8.jpg\n",
            "Processed: 76a8dccd-image-1.jpg\n",
            "Processed: 23ab7600-image-7.jpg\n",
            "Processed: 11d1d70c-image-2.jpg\n",
            "Processed: c5f6dfce-image-11.jpg\n",
            "Processed: 0c2e79e2-image-11.jpg\n",
            "Processed: ad4f5ac6-image-4.jpg\n",
            "Processed: 07680c1f-image-9.jpg\n",
            "Augmentation completed for all images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "def draw_yolo_bboxes(image_path, label_path):\n",
        "    \"\"\"\n",
        "    Reads an image and corresponding YOLO labels, then draws bounding boxes on the image.\n",
        "\n",
        "    Parameters:\n",
        "        image_path (str): Path to the rotated image.\n",
        "        label_path (str): Path to the rotated YOLO label file.\n",
        "\n",
        "    Saves:\n",
        "        Image with drawn bounding boxes as 'img_1_rotated_bbox.jpg'\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    with open(label_path, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        data = line.strip().split()\n",
        "        class_id, x_center, y_center, bbox_w, bbox_h = map(float, data)\n",
        "\n",
        "        # Convert YOLO format (normalized) to pixel values\n",
        "        x_center, y_center = int(x_center * w), int(y_center * h)\n",
        "        bbox_w, bbox_h = int(bbox_w * w), int(bbox_h * h)\n",
        "\n",
        "        # Get bounding box coordinates\n",
        "        x1 = int(x_center - bbox_w / 2)\n",
        "        y1 = int(y_center - bbox_h / 2)\n",
        "        x2 = int(x_center + bbox_w / 2)\n",
        "        y2 = int(y_center + bbox_h / 2)\n",
        "\n",
        "        # Draw rectangle and class label\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(image, f\"Class {int(class_id)}\", (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    # Save and display the image\n",
        "\n",
        "    save_img_path = os.path.join(\"/content/output/\",image_path.split(\"/\")[-1])\n",
        "    cv2.imwrite(save_img_path, image)\n",
        "    print(\"img saved at \", save_img_path)\n",
        "\n",
        "    # cv2.imshow(\"YOLO Bounding Boxes\", image)\n",
        "    # cv2.waitKey(0)\n",
        "    # cv2.destroyAllWindows()\n",
        "\n",
        "# Run the function\n",
        "os.mkdir(\"/content/output/\")\n",
        "for img_file in os.listdir(\"/content/rotated_images/\"):\n",
        "  img_path = \"/content/rotated_images/\" + img_file\n",
        "  label_path = \"/content/rotated_labels/\" + img_file[:-3] + \"txt\"\n",
        "  draw_yolo_bboxes(img_path, label_path)"
      ],
      "metadata": {
        "id": "PvcKOGW06QG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/dataset_v2/images/\", exist_ok=True)\n",
        "os.makedirs(\"/content/dataset_v2/labels/\", exist_ok=True)"
      ],
      "metadata": {
        "id": "tSimt3Wq6QFS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/images/* /content/dataset_v2/images/\n",
        "!cp -r /content/rotated_images/* /content/dataset_v2/images/\n",
        "!cp -r /content/labels/* /content/dataset_v2/labels/\n",
        "!cp -r /content/rotated_labels/* /content/dataset_v2/labels/"
      ],
      "metadata": {
        "id": "3-O3pqCM6P7j"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/images\n",
        "!rm -rf /content/labels\n",
        "!rm -rf /content/rotated_images/\n",
        "!rm -rf /content/rotated_labels/\n",
        "!rm -rf /content/output/"
      ],
      "metadata": {
        "id": "L592pPbx6P3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define augmentation pipeline (no geometric changes)\n",
        "transform = A.Compose([\n",
        "    A.RandomBrightnessContrast(\n",
        "     brightness_limit=0.2,\n",
        "     contrast_limit=0.2,\n",
        "     brightness_by_max=False,\n",
        "     p=0.3\n",
        "    ),\n",
        "\n",
        "    A.GaussianBlur(blur_limit=3, p=0.3),  # Light Gaussian blur\n",
        "    A.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1, p=0.4),\n",
        "\n",
        "\n",
        "    A.RandomGamma(p=1),               # Adjust gamma\n",
        "    A.RandomFog(fog_coef_lower=1, fog_coef_upper=1, p=0.3),\n",
        "    A.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
        "\n",
        "    # A.Blur(blur_limit=(5, 7), p=0.2),\n",
        "])\n",
        "# bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']),\n",
        "\n",
        "\n",
        "\n",
        "# Paths\n",
        "input_images = \"/content/dataset_v2/images/\"     # Original images folder\n",
        "input_labels = \"/content/dataset_v2/labels/\"     # Original Labels folder\n",
        "output_images = \"/content/dataset_v2/images_1/\"   # Augmented images folder\n",
        "output_labels = \"/content/dataset_v2/labels_1/\"\n",
        "\n",
        "\n",
        "os.makedirs(output_images, exist_ok=True)\n",
        "os.makedirs(output_labels, exist_ok=True)\n",
        "\n",
        "\n",
        "# Process images\n",
        "augment = 0\n",
        "for image_file in tqdm(os.listdir(input_images)):\n",
        "    if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "        img_path = os.path.join(input_images, image_file)\n",
        "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if img is not None:\n",
        "            # Apply augmentation\n",
        "            augmented = transform(image=img)[\"image\"]\n",
        "\n",
        "            # Save augmented image with a new name\n",
        "            output_img_file_path = f\"aug_{augment}_{image_file}\"\n",
        "            output_lbl_file_path = f\"aug_{augment}_{image_file[:-3]}\"+\"txt\"\n",
        "            output_img_path = os.path.join(output_images, output_img_file_path)\n",
        "            output_lbl_path = os.path.join(output_labels, output_lbl_file_path)\n",
        "\n",
        "            ## read the label.txt file\n",
        "            with open(os.path.join(input_labels, image_file[:-3]+\"txt\"), 'r') as infile:\n",
        "              content = infile.read()\n",
        "\n",
        "\n",
        "            ## save augmented images and label.txt\n",
        "            cv2.imwrite(output_img_path, augmented)\n",
        "            with open(output_lbl_path, \"w\") as outfile:\n",
        "                outfile.write(content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f\"original examples ---> {len(os.listdir(input_images))}\")\n",
        "print(f\"augmented examples ---> {len(os.listdir(output_images))}\")\n",
        "print(f\"total examples ---> {len(os.listdir(input_images)) + len(os.listdir(output_labels))}\")"
      ],
      "metadata": {
        "id": "8iYJijcz6a3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv  /content/dataset_v2/images_1/* /content/dataset_v2/images/\n",
        "!mv /content/dataset_v2/labels_1/* /content/dataset_v2/labels/"
      ],
      "metadata": {
        "id": "Vn8Xq55E6jtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/dataset_v2/images_1\n",
        "!rm -rf /content/dataset_v2/labels_1"
      ],
      "metadata": {
        "id": "YteDgx3u6jru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Source folder containing files\n",
        "source_folder = \"/content/dataset_v2/\"  # Replace with your folder path\n",
        "zip_filename = \"/content/custom-dataset-fractiion-imporovement.zip\"  # Destination zip file path\n",
        "\n",
        "# Create a new zip file\n",
        "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Walk through all directories and files\n",
        "    for root, _, files in os.walk(source_folder):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            # Preserve directory structure inside the zip\n",
        "            arcname = os.path.relpath(file_path, source_folder)\n",
        "            zipf.write(file_path, arcname=arcname)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"All files in '{source_folder}' have been zipped into '{zip_filename}'.\")\n",
        "print(f\"Size of zip file is {os.path.getsize(zip_filename)} bytes\")"
      ],
      "metadata": {
        "id": "6MeNSkCN6a1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy augmented zip file into drive\n",
        "!cp /content/custom-dataset-fractiion-imporovement.zip /content/drive/MyDrive/OCR-Custom-Dataset/"
      ],
      "metadata": {
        "id": "hrp3bcRC6P1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jN901JBy6w8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preperaing Dataset For Recognition Model"
      ],
      "metadata": {
        "id": "J96ltrJDuqbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "55eeHY-Gup6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import cv2\n",
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ZqU2R0iEuy6R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the yolo images into directory\n",
        "\n",
        "!unzip /content/project-3-at-2025-05-17-19-58-99bd2d3f.zip -d /content/"
      ],
      "metadata": {
        "id": "V2j5ntFwu1k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Json data file\n",
        "\n",
        "with open(\"/content/project-3-at-2025-05-20-14-35-1549ca81 (1).json\", 'r') as file:\n",
        "\n",
        "  labels = json.load(file)"
      ],
      "metadata": {
        "id": "K2a-wkpmu1jW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_root_dir = \"/content/images/\"\n",
        "lbl_root_dir = \"/content/labels/\"\n",
        "output_dir_train = \"./dataset/train/\"\n",
        "output_dir_test = \"./dataset/val/\"\n",
        "\n",
        "os.makedirs(output_dir_train, exist_ok=True)\n",
        "os.makedirs(output_dir_test, exist_ok=True)\n",
        "data_1 = []  # hold the examples (img_path, img)\n",
        "img_index = 0\n",
        "path_list = os.listdir(img_root_dir)\n",
        "print(f\"Dataset Size : {len(path_list)}\")"
      ],
      "metadata": {
        "id": "scx0LSjIu1fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20b3477-99ee-42f1-d038-b792ebaf4130"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size : 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## it can be used for both train and test directory and lables generation\n",
        "\n",
        "# Input:\n",
        "  # - images\n",
        "  # - labels.json\n",
        "\n",
        "# output:\n",
        "  # dataset\n",
        "  #   - train\n",
        "  #   - label.json  [img_path, transcription]\n",
        "\n",
        "\n",
        "\n",
        "for idx, label in enumerate(labels):\n",
        "  ## manuplate image path and read image\n",
        "  img_path = os.path.join(img_root_dir, label['ocr'].split('/')[-1])\n",
        "  image = cv.imread(img_path)\n",
        "\n",
        "\n",
        "  try:\n",
        "    ## iterate the bboxes and transcriptions\n",
        "    bbox = label['bbox']\n",
        "    transcription = label['transcription']\n",
        "\n",
        "  except KeyError:\n",
        "    continue\n",
        "\n",
        "  for i in range(len(bbox)):\n",
        "    # print(bbox[i], transcription[i])\n",
        "\n",
        "\n",
        "    ## extract xywh points\n",
        "    x_min = int(bbox[i]['x'] / 100 * bbox[i]['original_width'])\n",
        "    y_min = int(bbox[i]['y'] / 100 * bbox[i]['original_height'])\n",
        "    x_max = int(x_min + (bbox[i]['width'] / 100 * bbox[i]['original_width']))\n",
        "    y_max = int(y_min + (bbox[i]['height'] / 100 * bbox[i]['original_height']))\n",
        "\n",
        "    if type(transcription[i]) != str:\n",
        "      continue\n",
        "\n",
        "\n",
        "    ## cut the patches(words) from image\n",
        "    ## set directory structure of dataset (paddleOCR)\n",
        "    cropped_img = image[y_min:y_max, x_min:x_max]\n",
        "    cropped_img_transcription = transcription[i]\n",
        "\n",
        "\n",
        "    ## save image\n",
        "    output_img_path = os.path.join(output_dir_train, f\"crop_{i}_{label['ocr'].split('/')[-1]}\")\n",
        "    cv2.imwrite(output_img_path, cropped_img)\n",
        "\n",
        "\n",
        "\n",
        "    ## update text file\n",
        "    text_line = {\"image_path\" : f\"{output_img_path}\", \"text\" : cropped_img_transcription}\n",
        "    data_1.append(text_line)\n",
        "\n",
        "\n",
        "\n",
        "  print(f\"image saved at {output_img_path}\")\n",
        "\n",
        "\n",
        "\n",
        "with open(\"test_01.json\", \"w\") as file:\n",
        "  file.write(json.dumps(data_1))"
      ],
      "metadata": {
        "id": "a6nhzyX0u1eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Optional; only to be used whenever need test images from\n",
        "# the same labeled images\n",
        "## it can be used for test directory and lables generation\n",
        "\n",
        "# Input:\n",
        "  # - images\n",
        "  # - labels.json\n",
        "\n",
        "# output:\n",
        "  # dataset\n",
        "  #   - train\n",
        "  #   - label.json  [img_path, transcription]\n",
        "\n",
        "\n",
        "\n",
        "for idx, label in enumerate(labels):\n",
        "  ## manuplate image path and read image\n",
        "  img_path = os.path.join(img_root_dir, label['ocr'].split('/')[-1])\n",
        "  image = cv.imread(img_path)\n",
        "\n",
        "\n",
        "  try:\n",
        "    ## iterate the bboxes and transcriptions\n",
        "    bbox = label['bbox']\n",
        "    transcription = label['transcription']\n",
        "\n",
        "  except KeyError:\n",
        "    continue\n",
        "\n",
        "  for i in range(len(bbox)):\n",
        "    # print(bbox[i], transcription[i])\n",
        "\n",
        "\n",
        "    ## extract xywh points\n",
        "    x_min = int(bbox[i]['x'] / 100 * bbox[i]['original_width'])\n",
        "    y_min = int(bbox[i]['y'] / 100 * bbox[i]['original_height'])\n",
        "    x_max = int(x_min + (bbox[i]['width'] / 100 * bbox[i]['original_width']))\n",
        "    y_max = int(y_min + (bbox[i]['height'] / 100 * bbox[i]['original_height']))\n",
        "\n",
        "    if type(transcription[i]) != str:\n",
        "      continue\n",
        "\n",
        "\n",
        "    ## cut the patches(words) from image\n",
        "    ## set directory structure of dataset (paddleOCR)\n",
        "    cropped_img = image[y_min:y_max, x_min:x_max]\n",
        "    cropped_img_transcription = transcription[i]\n",
        "\n",
        "\n",
        "    ## save image\n",
        "    output_img_path = os.path.join(output_dir_test, f\"crop_{i}_{label['ocr'].split('/')[-1]}\")\n",
        "    cv2.imwrite(output_img_path, cropped_img)\n",
        "\n",
        "\n",
        "\n",
        "    ## update text file\n",
        "    text_line = {\"image_path\" : f\"{output_img_path}\", \"text\" : cropped_img_transcription}\n",
        "    data_1.append(text_line)\n",
        "\n",
        "\n",
        "\n",
        "  print(f\"image saved at {output_img_path}\")\n",
        "\n",
        "\n",
        "\n",
        "with open(\"02_custom-dataset-fractiion-imporovement_test.json\", \"w\") as file:\n",
        "  file.write(json.dumps(data_1))"
      ],
      "metadata": {
        "id": "_jBw5WVzvpEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Source folder containing files\n",
        "source_folder = \"/content/dataset\"  # Replace with your folder path\n",
        "zip_filename = \"/content/02_custom-dataset-fractiion-imporovement.zip\"  # Destination zip file path\n",
        "\n",
        "# Create a new zip file\n",
        "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Walk through all directories and files\n",
        "    for root, _, files in os.walk(source_folder):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            # Preserve directory structure inside the zip\n",
        "            arcname = os.path.relpath(file_path, source_folder)\n",
        "            zipf.write(file_path, arcname=arcname)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"All files in '{source_folder}' have been zipped into '{zip_filename}'.\")\n",
        "print(f\"Size of zip file is {os.path.getsize(zip_filename)} bytes\")"
      ],
      "metadata": {
        "id": "U3qhOjTDu-vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/02_custom-dataset-fractiion-imporovement.zip /content/drive/MyDrive/OCR-Custom-Dataset/"
      ],
      "metadata": {
        "id": "wzUTq8TIu-tU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}